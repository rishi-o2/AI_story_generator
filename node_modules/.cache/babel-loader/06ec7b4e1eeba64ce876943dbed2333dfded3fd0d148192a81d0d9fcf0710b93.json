{"ast":null,"code":"import _objectSpread from \"E:/Chat_bot_intership/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\nimport _classCallCheck from \"E:/Chat_bot_intership/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"E:/Chat_bot_intership/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"E:/Chat_bot_intership/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"E:/Chat_bot_intership/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n// File generated from our OpenAPI spec by Stainless.\nimport { APIResource } from 'openai/resource';\nexport var Edits = /*#__PURE__*/function (_APIResource) {\n  _inherits(Edits, _APIResource);\n  var _super = _createSuper(Edits);\n  function Edits() {\n    _classCallCheck(this, Edits);\n    return _super.apply(this, arguments);\n  }\n  _createClass(Edits, [{\n    key: \"create\",\n    value:\n    /**\n     * Creates a new edit for the provided input, instruction, and parameters.\n     *\n     * @deprecated The Edits API is deprecated; please use Chat Completions instead.\n     *\n     * https://openai.com/blog/gpt-4-api-general-availability#deprecation-of-the-edits-api\n     */\n    function create(body, options) {\n      return this.post('/edits', _objectSpread({\n        body: body\n      }, options));\n    }\n  }]);\n  return Edits;\n}(APIResource);\n(function (Edits) {})(Edits || (Edits = {}));","map":{"version":3,"names":["APIResource","Edits","_APIResource","_inherits","_super","_createSuper","_classCallCheck","apply","arguments","_createClass","key","value","body","options","post","_objectSpread"],"sources":["E:\\Chat_bot_intership\\node_modules\\openai\\src\\resources\\edits.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from '../core.js';\nimport { APIResource } from '../resource.js';\nimport * as Completions from './completions.js';\nimport * as API from './index.js';\n\nexport class Edits extends APIResource {\n  /**\n   * Creates a new edit for the provided input, instruction, and parameters.\n   *\n   * @deprecated The Edits API is deprecated; please use Chat Completions instead.\n   *\n   * https://openai.com/blog/gpt-4-api-general-availability#deprecation-of-the-edits-api\n   */\n  create(body: EditCreateParams, options?: Core.RequestOptions): Core.APIPromise<Edit> {\n    return this.post('/edits', { body, ...options });\n  }\n}\n\nexport interface Edit {\n  /**\n   * A list of edit choices. Can be more than one if `n` is greater than 1.\n   */\n  choices: Array<Edit.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the edit was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always `edit`.\n   */\n  object: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage: Completions.CompletionUsage;\n}\n\nexport namespace Edit {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, or `length` if the maximum\n     * number of tokens specified in the request was reached.\n     */\n    finish_reason: 'stop' | 'length';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * The edited result.\n     */\n    text: string;\n  }\n}\n\nexport interface EditCreateParams {\n  /**\n   * The instruction that tells the model how to edit the prompt.\n   */\n  instruction: string;\n\n  /**\n   * ID of the model to use. You can use the `text-davinci-edit-001` or\n   * `code-davinci-edit-001` model with this endpoint.\n   */\n  model: (string & {}) | 'text-davinci-edit-001' | 'code-davinci-edit-001';\n\n  /**\n   * The input text to use as a starting point for the edit.\n   */\n  input?: string | null;\n\n  /**\n   * How many edits to generate for the input and instruction.\n   */\n  n?: number | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Edits {\n  export import Edit = API.Edit;\n  export import EditCreateParams = API.EditCreateParams;\n}\n"],"mappings":";;;;;AAAA;SAGSA,WAAW,QAAQ,iBAAiB;AAI7C,WAAaC,KAAM,0BAAAC,YAAA;EAAAC,SAAA,CAAAF,KAAA,EAAAC,YAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,KAAA;EAAA,SAAAA,MAAA;IAAAK,eAAA,OAAAL,KAAA;IAAA,OAAAG,MAAA,CAAAG,KAAA,OAAAC,SAAA;EAAA;EAAAC,YAAA,CAAAR,KAAA;IAAAS,GAAA;IAAAC,KAAA;;;;;;;;oBAQjBC,IAAO,EAAsBC,OAAE,EAA6B;aAC1D,IAAO,CAAAC,IAAK,SAAK,EAAAC,aAAA;QAAQH,IAAI,EAAJA;MAAI,GAAIC,OAAK;;;;EATfb,WAAW;AAiGtC,WAAiBC,KAAK,MAAAA,KAAA,KAAAA,KAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}